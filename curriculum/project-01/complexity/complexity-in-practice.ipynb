{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse String Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:12:56.503970Z",
     "start_time": "2019-04-05T21:12:56.498354Z"
    }
   },
   "outputs": [],
   "source": [
    "def reverse_string(input_string):\n",
    "    \"\"\"First reverse string solution\"\"\"\n",
    "    output_string = \"\"\n",
    "    \n",
    "    for character in input_string:\n",
    "        \n",
    "        output_string = character + output_string\n",
    "    \n",
    "    return output_string\n",
    "\n",
    "assert reverse_string('abcdef') == 'fedcba'\n",
    "assert reverse_string('moon') == 'noom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:12:56.516421Z",
     "start_time": "2019-04-05T21:12:56.510434Z"
    }
   },
   "outputs": [],
   "source": [
    "# slice syntax [start:stop:step] and each has reasonable default values\n",
    "\n",
    "def reverse_string_2(input_string):\n",
    "    \"\"\"Second reverse string solution\"\"\"\n",
    "    return input_string[::-1]\n",
    "\n",
    "assert reverse_string_2('abcdef') == 'fedcba'\n",
    "assert reverse_string_2('moon') == 'noom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can You Spell Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:12:56.544634Z",
     "start_time": "2019-04-05T21:12:56.537159Z"
    }
   },
   "outputs": [],
   "source": [
    "# can_you_spell(['y','n','p','g','n','l'],\"lynn\") would print YES\n",
    "\n",
    "def can_you_spell(lol, word):\n",
    "    \"\"\"First can you spell solution\"\"\"\n",
    "    for letter in word:\n",
    "        if letter in lol:\n",
    "            lol.remove(letter)\n",
    "        else:\n",
    "            return \"NO\"\n",
    "    return \"YES\"\n",
    "\n",
    "assert can_you_spell(['y','n','p','g','n','l'],\"lynn\") == \"YES\"\n",
    "assert can_you_spell(['y','n','p','g','l'],\"lynn\") == \"NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:12:56.557612Z",
     "start_time": "2019-04-05T21:12:56.548688Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def can_you_spell_2(letters, word):\n",
    "    \"\"\"Second can you spell solution\"\"\"\n",
    "    letters_counter = Counter(letters)\n",
    "    word_counter = Counter(word)\n",
    "    for k in word_counter.keys():\n",
    "        if word_counter[k] > letters_counter[k]:\n",
    "            return \"NO\"\n",
    "    return \"YES\"\n",
    "    \n",
    "assert can_you_spell_2(['y','n','p','g','n','l'],\"lynn\") == \"YES\"\n",
    "assert can_you_spell_2(['y','n','p','g','l'],\"lynn\") == \"NO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall clock\n",
    "\n",
    "First, we'll look at different ways to measure time complexity using \"wall clock\" or the time an algorithm takes to run while we're sipping our coffee and twiddling our thumbs.\n",
    "\n",
    "Note that measuring an algorithm with a \"wall clock\" is somewhat noisy. If Slack is loading a bunch of gifs in the background, it's going to affect the amount of time our algorithm takes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single measurement\n",
    "\n",
    "First, we'll use cell magic to time a single line.\n",
    "\n",
    "We can use string multiplication to copy the input string many times and vary that multiplication to see how the size of the input affects the runtime of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:07.210323Z",
     "start_time": "2019-04-05T21:12:56.565309Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit reverse_string('abcdef'*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:10.122079Z",
     "start_time": "2019-04-05T21:13:07.213604Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit reverse_string_2('abcdef'*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:19.960803Z",
     "start_time": "2019-04-05T21:13:10.125438Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit can_you_spell(['y','n','p','g','n', 'l']*100,\"lynn\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:23.536418Z",
     "start_time": "2019-04-05T21:13:19.964080Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit can_you_spell_2(['y','n','p','g','n', 'l']*100,\"lynn\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programatic measurement of wall clock using timeit module\n",
    "\n",
    "Running a single line gives us some insight into the complexity of these algorithms, but we can add some rigor to our investigation by testing the algorithm at many different input sizes and keeping track of our measurements.\n",
    "\n",
    "In the above code, jupyter intelligently guesses how many times to run the command so that it gets in as many runs as it can without taking too long. Having a lot of measurements is good because of the variability in wall clock measurements. In the code below, though, we want to set up the same testing condition for each input size, so we'll manually set the number of runs. Explore the [`timeit`](https://docs.python.org/3/library/timeit.html) documentation for more information on the arguments we're using.\n",
    "\n",
    "One particular part is worth quoting:\n",
    "\n",
    "> It’s tempting to calculate mean and standard deviation from the result vector and report these. However, this is not very useful. In a typical case, the lowest value gives a lower bound for how fast your machine can run the given code snippet; higher values in the result vector are typically not caused by variability in Python’s speed, but by other processes interfering with your timing accuracy. So the **`min()`** of the result is probably the only number you should be interested in. After that, you should look at the entire vector and apply common sense rather than statistics.\n",
    "\n",
    "We'll follow the recommendation and use `min()` below.\n",
    "\n",
    "\n",
    "Finally, the way timeit works is that it executes the command we pass it in a separate python interpreter. In order to use functions and variables we've defined, we have to manually pass those to the module. The lazy way to do this is to pass it everything we've defined so far with `globals()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:24.548067Z",
     "start_time": "2019-04-05T21:13:23.538677Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:24.670298Z",
     "start_time": "2019-04-05T21:13:24.551803Z"
    }
   },
   "outputs": [],
   "source": [
    "# how to use timeit programatically \n",
    "# a single run\n",
    "\n",
    "num_loops = 100\n",
    "num_repeats = 10\n",
    "runtime = min(\n",
    "    timeit.repeat(\n",
    "        'reverse_string(\"abcdef\"*100)',\n",
    "        globals=globals(),\n",
    "        repeat=num_repeats,\n",
    "        number=num_loops))\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse String Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:35.174425Z",
     "start_time": "2019-04-05T21:13:24.674491Z"
    }
   },
   "outputs": [],
   "source": [
    "num_loops = 100\n",
    "num_repeats = 10\n",
    "\n",
    "rev_1_times = []\n",
    "rev_2_times = []\n",
    "lengths = list(range(1,1000,50)) # this is where we define the input sizes we'll use\n",
    "for i in lengths:\n",
    "    \n",
    "    runtime = min(\n",
    "        timeit.repeat(\n",
    "            f'reverse_string(\"abcdef\"*{i})',\n",
    "            globals=globals(),\n",
    "            repeat=num_repeats,\n",
    "            number=num_loops))\n",
    "    rev_1_times.append(runtime)\n",
    "    \n",
    "    runtime = min(\n",
    "        timeit.repeat(\n",
    "            f'reverse_string_2(\"abcdef\"*{i})',\n",
    "            globals=globals(),\n",
    "            repeat=num_repeats,\n",
    "            number=num_loops))\n",
    "    rev_2_times.append(runtime)\n",
    "    \n",
    "plot(lengths, rev_1_times, label=\"time to run `reverse_string('abcdef'*{i})`\")\n",
    "plot(lengths, rev_2_times, label=\"time to run `reverse_string_2('abcdef'*{i})`\")\n",
    "legend()\n",
    "xlabel(\"i\")\n",
    "ylabel(\"runtime (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:35.525712Z",
     "start_time": "2019-04-05T21:13:35.177708Z"
    }
   },
   "outputs": [],
   "source": [
    "# reverse_string_2 looks constant but that's unexpected. \n",
    "# Let's see it on its own.\n",
    "\n",
    "plot(lengths, rev_2_times, label=\"time to run `reverse_string_2('abcdef'*{i})`\")\n",
    "legend()\n",
    "xlabel(\"i\")\n",
    "ylabel(\"runtime (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "`reverse_string` and `reverse_string_2` both likely have $O(n)$ runtime. But not all $O(n)$ functions are equal! Here we can see that the constant multiplier makes a huge difference in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can You Spell Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:35.538794Z",
     "start_time": "2019-04-05T21:13:35.532528Z"
    }
   },
   "outputs": [],
   "source": [
    "fun_to_run = [\n",
    "    \"can_you_spell(['h','i','y']*{i},'hi'*{i})\",\n",
    "    \"can_you_spell_2(['h','i','y']*{i},'hi'*{i})\"\n",
    "]\n",
    "fun = fun_to_run[0]\n",
    "fun.format(i=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.026397Z",
     "start_time": "2019-04-05T21:13:35.542503Z"
    }
   },
   "outputs": [],
   "source": [
    "# case where n=m\n",
    "\n",
    "num_loops = 500\n",
    "num_repeats = 10\n",
    "\n",
    "\n",
    "fun_to_run = [\n",
    "    \"can_you_spell(['h','i','y']*{i},'hi'*{i})\",\n",
    "    \"can_you_spell_2(['h','i','y']*{i},'hi'*{i})\"\n",
    "]\n",
    "\n",
    "lengths = list(range(1,100,5))\n",
    "runtimes = []\n",
    "for fun in fun_to_run:\n",
    "    fun_runtimes = []\n",
    "    for i in lengths:\n",
    "        runtime = min(\n",
    "            timeit.repeat(\n",
    "                fun.format(i=i),\n",
    "                globals=globals(),\n",
    "                repeat=num_repeats,\n",
    "                number=num_loops))\n",
    "        fun_runtimes.append(runtime)\n",
    "    runtimes.append(fun_runtimes)\n",
    "\n",
    "plot(lengths, runtimes[0], label=f\"time to run `{fun_to_run[0]}`\")\n",
    "plot(lengths, runtimes[1], label=f\"time to run `{fun_to_run[1]}`\")\n",
    "legend()\n",
    "xlabel(\"i\")\n",
    "ylabel(\"runtime (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e7739f47eaedd74",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Check for understanding\n",
    "\n",
    "What do the above results say about our two competing algorithms, `can_you_spell` and `can_you_spell2`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ab9720301a24363a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8a6b162528c6c29",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### We Code\n",
    "\n",
    "> The above cell looks at cases where the lenth of the input characters $n$ and the length of the query string $m$ are roughly equal $n=m$. Modify that code to test 2 new cases\n",
    ">\n",
    "> 1) the case where $n$ is much greater than $m$, $n>>m$.\n",
    ">\n",
    "> 2) the case where $m$ is much greater than $n$, $m>>n$.\n",
    "\n",
    "(Give students about 5 minutes to work on this. After, ask students how they solved and display solution below if none of the students arrived at it) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.031229Z",
     "start_time": "2019-04-05T21:13:48.028605Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4246e5c89b061bec",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# case where n>>m\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "num_loops = 500\n",
    "num_repeats = 10\n",
    "\n",
    "fun_to_run = [\n",
    "    \"can_you_spell(['h','i','y']*{i},'hi'*2)\",\n",
    "    \"can_you_spell_2(['h','i','y']*{i},'hi'*2)\"\n",
    "]\n",
    "\n",
    "lengths = list(range(1,100,5))\n",
    "runtimes = []\n",
    "for fun in fun_to_run:\n",
    "    fun_runtimes = []\n",
    "    for i in lengths:\n",
    "        runtime = mean(\n",
    "            timeit.repeat(\n",
    "                fun.format(i=i),\n",
    "                globals=globals(),\n",
    "                repeat=num_repeats,\n",
    "                number=num_loops))\n",
    "        fun_runtimes.append(runtime)\n",
    "    runtimes.append(fun_runtimes)\n",
    "\n",
    "plot(lengths, runtimes[0], label=f\"time to run `{fun_to_run[0]}`\")\n",
    "plot(lengths, runtimes[1], label=f\"time to run `{fun_to_run[1]}`\")\n",
    "legend()\n",
    "xlabel(\"i\")\n",
    "ylabel(\"runtime (s)\")\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.039618Z",
     "start_time": "2019-04-05T21:13:48.034252Z"
    }
   },
   "outputs": [],
   "source": [
    "# case where m>>n\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "num_loops = 500\n",
    "num_repeats = 10\n",
    "\n",
    "fun_to_run = [\n",
    "    \"can_you_spell(['h','i','y']*2,'hi'*{i})\",\n",
    "    \"can_you_spell_2(['h','i','y']*2,'hi'*{i})\"\n",
    "]\n",
    "\n",
    "lengths = list(range(1,100,5))\n",
    "runtimes = []\n",
    "for fun in fun_to_run:\n",
    "    fun_runtimes = []\n",
    "    for i in lengths:\n",
    "        runtime = mean(\n",
    "            timeit.repeat(\n",
    "                fun.format(i=i),\n",
    "                globals=globals(),\n",
    "                repeat=num_repeats,\n",
    "                number=num_loops))\n",
    "        fun_runtimes.append(runtime)\n",
    "    runtimes.append(fun_runtimes)\n",
    "\n",
    "plot(lengths, runtimes[0], label=f\"time to run `{fun_to_run[0]}`\")\n",
    "plot(lengths, runtimes[1], label=f\"time to run `{fun_to_run[1]}`\")\n",
    "legend()\n",
    "xlabel(\"i\")\n",
    "ylabel(\"runtime (s)\")\n",
    "\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b2e285c617f245e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Check for understanding\n",
    "\n",
    "With these new results, what can we say about `can_you_spell` and `can_you_spell2`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-db6e88f3c31f45ec",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Conclusions:\n",
    "\n",
    "When $n >> m$ or $m >> n$, both `can_you_spell` seems to have constant runtime $O(1)$ and  `can_you_spell_2` seems to have linear runtime $O(n)$ or $O(m)$.\n",
    "\n",
    "However, when $n=m$, `can_you_spell` appears to have $O(n*m)$ runtime while `can_you_spell_2` seems closer to linear $O(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using lprun\n",
    "\n",
    "\n",
    "While the wall clock method can be quite useful, we often want to get at a more general measure of time complexity, the big-O complexity discussed in lecture. A very helpful technique for this is to use a line profiler that counts the number of executions for each line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.047325Z",
     "start_time": "2019-04-05T21:13:48.043100Z"
    }
   },
   "outputs": [],
   "source": [
    "# install line_profiler  if you need them\n",
    "\n",
    "# !conda install -n metis line_profiler -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.063654Z",
     "start_time": "2019-04-05T21:13:48.050363Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.075268Z",
     "start_time": "2019-04-05T21:13:48.066985Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000; m = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T21:13:48.242383Z",
     "start_time": "2019-04-05T21:13:48.080743Z"
    }
   },
   "outputs": [],
   "source": [
    "%lprun -f can_you_spell  can_you_spell(['y','n','p','g','n', 'l']*n,\"lynn\"*m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d545ec1b9143ff99",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## You code\n",
    "\n",
    "Use the above example to profile the above code using different values of `m` and `n`.\n",
    "\n",
    "Given the results you see, write out the **full equation** in terms of execution of lines for $f(n)$. \n",
    "\n",
    "Once you've done this, simplify your result to big-O complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T19:10:21.586634Z",
     "start_time": "2019-04-08T19:10:21.555728Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-136048bb424caf51",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "| m | n | count | \n",
    "|---|---|-------|\n",
    "| 1000 | 1000 | 120,000 |\n",
    "| 100 | 100 | 1,200 |\n",
    "| 10 | 10 | 120 |\n",
    "| 1000 | 10 | 120 |\n",
    "| 10 | 1000 | 120 |\n",
    "| 1000 | 100 | 1,200 |\n",
    "\n",
    "From this it appears that $f(n) = 1.2(\\min(m,n)^2)$\n",
    "\n",
    "Using the heuristic method, we can say that $f(n) = O(\\min(m,n)^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
